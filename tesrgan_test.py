# -*- coding: utf-8 -*-
"""tesrgan_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X6Z-wcf_AUnL2k_o5R9jdisFjBII70Yt
"""

# Install required packages
!pip install torch torchvision pillow matplotlib kaggle

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
from PIL import Image
import os
import matplotlib.pyplot as plt
from google.colab import drive

# Mount Google Drive for model saving
drive.mount('/content/drive')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Import dependencies
import torch
import torch.nn as nn
from torchvision import transforms


# === Define All Components First ===

class PatchEmbed(nn.Module):
    def __init__(self, img_size=32, patch_size=8, in_chans=64, embed_dim=512):
        super().__init__()
        self.num_patches = (img_size // patch_size) ** 2
        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)

    def forward(self, x):
        x = self.proj(x).flatten(2).transpose(1, 2)
        return x

class TransformerBlock(nn.Module):
    def __init__(self, embed_dim=512, num_heads=8):
        super().__init__()
        self.norm1 = nn.LayerNorm(embed_dim)
        self.attn = nn.MultiheadAttention(embed_dim, num_heads)
        self.norm2 = nn.LayerNorm(embed_dim)
        self.mlp = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 4),
            nn.GELU(),
            nn.Linear(embed_dim * 4, embed_dim)
        )

    def forward(self, x):
        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]
        x = x + self.mlp(self.norm2(x))
        return x

class ViTEnhancer(nn.Module):
    def __init__(self):
        super().__init__()
        self.blocks = nn.ModuleList([TransformerBlock() for _ in range(3)])

    def forward(self, x):
        for block in self.blocks:
            x = block(x)
        return x

class ResidualDenseBlock_5C(nn.Module):
    def __init__(self, nf=64, gc=32):
        super().__init__()
        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1)
        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1)
        self.conv3 = nn.Conv2d(nf + 2*gc, gc, 3, 1, 1)
        self.conv4 = nn.Conv2d(nf + 3*gc, gc, 3, 1, 1)
        self.conv5 = nn.Conv2d(nf + 4*gc, nf, 3, 1, 1)

    def forward(self, x):
        x1 = torch.relu(self.conv1(x))
        x2 = torch.relu(self.conv2(torch.cat((x, x1), 1)))
        x3 = torch.relu(self.conv3(torch.cat((x, x1, x2), 1)))
        x4 = torch.relu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 + x

# === Then Define Generator ===

class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.scale = 4
        self.conv_first = nn.Conv2d(3, 64, 3, 1, 1)
        self.RRDB_trunk = nn.Sequential(*[ResidualDenseBlock_5C() for _ in range(23)])
        self.trunk_conv = nn.Conv2d(64, 64, 3, 1, 1)

        # Transformer Enhancement
        self.patch_embed = PatchEmbed()
        self.vit = ViTEnhancer()
        self.patch_unembed = nn.ConvTranspose2d(512, 64, kernel_size=8, stride=8)

        # Upsampling
        self.upconv1 = nn.Conv2d(64, 64 * 4, 3, 1, 1)
        self.upconv2 = nn.Conv2d(64, 64 * 4, 3, 1, 1)
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

    def forward(self, x):
        fea = self.conv_first(x)
        trunk = self.trunk_conv(self.RRDB_trunk(fea)) + fea

        # Transformer Enhancement
        B, C, H, W = trunk.shape
        vit_input = self.patch_embed(trunk)
        vit_output = self.vit(vit_input)
        vit_output = vit_output.transpose(1, 2).view(B, 512, H//8, W//8)
        vit_output = self.patch_unembed(vit_output)
        trunk = trunk + vit_output

        # Upsampling
        out = self.pixel_shuffle(self.upconv1(trunk))
        out = self.pixel_shuffle(self.upconv2(out))
        out = self.conv_last(out)
        return torch.tanh(out)

    def forward(self, x):
        # Forward pass
      return x

from google.colab import files

# Upload multiple files at once
uploaded = files.upload()



import os

file_path = "/content/drive/MyDrive/esrgan_transformer_model.pth"

# Check if file exists
if os.path.exists(file_path):
    size = os.path.getsize(file_path)
    print(f"‚úÖ File exists. Size: {size / (1024 * 1024):.2f} MB")
else:
    print("‚ùå File does NOT exist.")

import torch

try:
    data = torch.load("esrgan_transformer_model.pth", map_location="cpu")
    print("üîç Loaded file contents:")
    print(type(data))
except Exception as e:
    print("‚ùå Error loading file:", str(e))

model = Generator()
model.load_state_dict(torch.load("esrgan_transformer_model.pth", map_location="cpu"))
model.eval()

from PIL import Image
from torchvision import transforms

# Load image
img = Image.open("/content/drive/MyDrive/dataset_ver/10.jpg").convert("RGB")
transform = transforms.ToTensor()
img_tensor = transform(img).unsqueeze(0)  # Add batch dim

# Run inference
with torch.no_grad():
    output = model(img_tensor)

# Save output
from torchvision.utils import save_image
save_image(output, "/content/sr_output.png")
print("üì∑ Super-resolved image saved!")

from google.colab import files

print("Please upload your test image(s) (.jpg, .png):")
uploaded = files.upload()

# Save file names
image_paths = list(uploaded.keys())
print(f"‚úÖ Uploaded {len(image_paths)} image(s).")

from torchvision import transforms
from PIL import Image

# Image transform
transform = transforms.Compose([
    transforms.ToTensor(),
])

import os
from torchvision.utils import save_image

# Create output folder
output_dir = "/content/sr_output"
os.makedirs(output_dir, exist_ok=True)

for img_name in image_paths:
    # Load image
    img = Image.open(img_name).convert("RGB")
    img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dim

    # Run inference
    with torch.no_grad():
        sr_img = model(img_tensor)

    # Post-process and save
    sr_img = sr_img.squeeze(0).cpu()
    output_path = os.path.join(output_dir, f"sr_{img_name}")
    save_image(sr_img, output_path)

    print(f"üì∑ Saved super-resolved image: {output_path}")

# Zip results
!zip -r sr_results.zip /content/sr_output/

# Download zip file
from google.colab import files
files.download("sr_results.zip")

import matplotlib.pyplot as plt

# Pick first image
original = Image.open(image_paths[0]).convert("RGB")
sr_image = Image.open(os.path.join(output_dir, f"sr_{image_paths[0]}")).convert("RGB")

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.title("Original")
plt.imshow(original)

plt.subplot(1, 2, 2)
plt.title("Super-Resolved")
plt.imshow(sr_image)

plt.show()

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import numpy as np

def evaluate_model(model, dataloader):
    model.eval()
    total_psnr = 0
    total_ssim = 0
    count = 0

    with torch.no_grad():
        for lr, hr in dataloader:
            lr, hr = lr.to(device), hr.to(device)
            sr = model(lr)

            sr_img = sr.clamp(0, 1).cpu().numpy()
            hr_img = hr.clamp(0, 1).cpu().numpy()

            for i in range(sr_img.shape[0]):
                p = psnr(hr_img[i].transpose(1,2,0), sr_img[i].transpose(1,2,0))
                s = ssim(hr_img[i].transpose(1,2,0), sr_img[i].transpose(1,2,0), multichannel=True, channel_axis=2)
                total_psnr += p
                total_ssim += s
                count += 1

    return total_psnr / count, total_ssim / count

from google.colab import files
import zipfile
import os

# Step 1: Upload zip file
print("Please upload sr_images.zip:")
uploaded = files.upload()

zip_path = list(uploaded.keys())[0]
extract_folder = "/content/sr_images"
os.makedirs(extract_folder, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"‚úÖ Extracted {len(os.listdir(extract_folder))} SR images to '{extract_folder}/'")

hr_folder = "/content/drive/MyDrive/dataset_ver"

if not os.path.exists(hr_folder):
    print("‚ùå HR folder not found. Please upload or define it.")
else:
    print(f"‚úÖ Found HR images at: {hr_folder}")

import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt



def evaluate_images(sr_folder, hr_folder):
    sr_files = sorted([f for f in os.listdir(sr_folder) if f.endswith(('.png', '.jpg'))])
    hr_files = sorted([f for f in os.listdir(hr_folder) if f.endswith(('.png', '.jpg'))])

    psnrs = []
    ssims = []
    filenames = []

    print("üìä Evaluating SR vs HR image pairs:")

    for sr_file, hr_file in zip(sr_files, hr_files):
        sr_path = os.path.join(sr_folder, sr_file)
        hr_path = os.path.join(hr_folder, hr_file)

        # Read images
        sr_img = cv2.imread(sr_path)
        hr_img = cv2.imread(hr_path)

        # Resize if needed
        sr_img = cv2.resize(sr_img, (hr_img.shape[1], hr_img.shape[0]))

        # Convert to YCbCr
        def to_ycbcr(img):
            return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

        hr_y = to_ycbcr(hr_img)[:, :, 0]
        sr_y = to_ycbcr(sr_img)[:, :, 0]

        p = psnr(hr_y, sr_y)
        s = ssim(hr_y, sr_y)

        psnrs.append(p)
        ssims.append(s)
        filenames.append(sr_file)

        print(f"{sr_file} -> PSNR: {p:.2f} dB, SSIM: {s:.4f}")

    avg_psnr = np.mean(psnrs)
    avg_ssim = np.mean(ssims)

    print("\nüìà Average Results:")
    print(f"PSNR: {avg_psnr:.2f} dB")
    print(f"SSIM: {avg_ssim:.4f}")

    return filenames, psnrs, ssims


# Run evaluation
filenames, psnrs, ssims = evaluate_images("/content/sr_images/", "/content/drive/MyDrive/dataset_ver")

sr_folder = "/content/sr_images"
sr_files = sorted([f for f in os.listdir(sr_folder) if f.endswith(('.png', '.jpg'))])
print("üìÑ Found SR files:", sr_files)

# List all contents of the extracted folder
print("üìÑ Files in SR folder:")
for root, dirs, files in os.walk(extract_folder):
    for name in files:
        print(os.path.join(root, name))

hr_folder = "/content/drive/MyDrive/dataset_ver"

if not os.path.exists(hr_folder):
    print("‚ùå HR folder not found. Please upload or define it.")
else:
    print(f"‚úÖ Found HR images at: {hr_folder}")



import shutil

def move_images_to_root(folder):
    for root, _, files in os.walk(folder):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                src_path = os.path.join(root, file)
                dst_path = os.path.join(folder, file)
                if src_path != dst_path:  # Avoid self-move
                    shutil.move(src_path, dst_path)

# Run after extraction
move_images_to_root(extract_folder)
print("‚úÖ Moved all images to root folder.")

import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

def evaluate_images(sr_folder, hr_folder):
    sr_files = sorted([f for f in os.listdir(sr_folder) if f.endswith(('.png', '.jpg'))])
    hr_files = sorted([f for f in os.listdir(hr_folder) if f.endswith(('.png', '.jpg'))])

    psnrs = []
    ssims = []
    filenames = []

    print("üìä Evaluating SR vs HR image pairs:")

    for sr_file, hr_file in zip(sr_files, hr_files):
        sr_path = os.path.join(sr_folder, sr_file)
        hr_path = os.path.join(hr_folder, hr_file)

        # Read images
        sr_img = cv2.imread(sr_path)
        hr_img = cv2.imread(hr_path)

        # Resize if needed
        sr_img = cv2.resize(sr_img, (hr_img.shape[1], hr_img.shape[0]))

        # Convert to YCbCr
        def to_ycbcr(img):
            return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

        hr_y = to_ycbcr(hr_img)[:, :, 0]
        sr_y = to_ycbcr(sr_img)[:, :, 0]

        p = psnr(hr_y, sr_y)
        s = ssim(hr_y, sr_y)

        psnrs.append(p)
        ssims.append(s)
        filenames.append(sr_file)

        print(f"{sr_file} -> PSNR: {p:.2f} dB, SSIM: {s:.4f}")

    avg_psnr = np.mean(psnrs)
    avg_ssim = np.mean(ssims)

    print("\nüìà Average Results:")
    print(f"PSNR: {avg_psnr:.2f} dB")
    print(f"SSIM: {avg_ssim:.4f}")

    return filenames, psnrs, ssims


# Run evaluation
filenames, psnrs, ssims = evaluate_images("/content/sr_images/", "/content/drive/MyDrive/dataset_ver")

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.bar(filenames, psnrs, color='skyblue')
plt.xticks(rotation=90)
plt.title('PSNR per Image')
plt.ylabel('dB')

plt.subplot(1, 2, 2)
plt.bar(filenames, ssims, color='salmon')
plt.xticks(rotation=90)
plt.title('SSIM per Image')
plt.ylabel('Score')

plt.tight_layout()
plt.show()

filenames, psnrs, ssims = evaluate_images("/content/sr_images", "/content/drive/MyDrive/dataset_ver")

import os
from PIL import Image
import matplotlib.pyplot as plt

# Paths
hr_folder = "/content/drive/MyDrive/dataset_ver"
sr_folder = "/content/sr_images"

# Get matching image files
hr_files = sorted([f for f in os.listdir(hr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
sr_files = sorted([f for f in os.listdir(sr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

# Limit number of images to show (optional)
num_images_to_show = min(5, len(hr_files), len(sr_files))

# Function to calculate PSNR and SSIM
def get_psnr_ssim(hr_path, sr_path):
    import cv2
    from skimage.metrics import peak_signal_noise_ratio as psnr
    from skimage.metrics import structural_similarity as ssim

    hr_img = cv2.imread(hr_path)
    sr_img = cv2.imread(sr_path)

    # Resize if needed
    sr_img = cv2.resize(sr_img, (hr_img.shape[1], hr_img.shape[0]))

    # Convert to YCbCr
    def to_ycbcr(img):
        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

    hr_y = to_ycbcr(hr_img)[:, :, 0]
    sr_y = to_ycbcr(sr_img)[:, :, 0]

    p = psnr(hr_y, sr_y)
    s = ssim(hr_y, sr_y)
    return p, s

# Plot side-by-side comparisons
fig, axes = plt.subplots(num_images_to_show, 2, figsize=(12, 3 * num_images_to_show))

for i in range(num_images_to_show):
    hr_img = Image.open(os.path.join(hr_folder, hr_files[i]))
    sr_img = Image.open(os.path.join(sr_folder, sr_files[i]))

    hr_path = os.path.join(hr_folder, hr_files[i])
    sr_path = os.path.join(sr_folder, sr_files[i])
    psnr_val, ssim_val = get_psnr_ssim(hr_path, sr_path)

    # HR image
    axes[i, 0].imshow(hr_img)
    axes[i, 0].set_title(f"HR - {hr_files[i]}")
    axes[i, 0].axis('off')

    # SR image
    axes[i, 1].imshow(sr_img)
    axes[i, 1].set_title(f"SR - {sr_files[i]}\nPSNR: {psnr_val:.2f} dB | SSIM: {ssim_val:.4f}")
    axes[i, 1].axis('off')

plt.tight_layout()
plt.show()

import os
from PIL import Image
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

# Paths
hr_folder = "/content/drive/MyDrive/dataset_ver"
sr_folder = "/content/sr_images"

# Get matching image files
hr_files = sorted([f for f in os.listdir(hr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
sr_files = sorted([f for f in os.listdir(sr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

# Ensure same number of files
num_images = min(len(hr_files), len(sr_files))
print(f"üì∑ Found {num_images} matching image pairs.")

# Function to compute PSNR and SSIM
def get_psnr_ssim(hr_path, sr_path):
    hr_img = cv2.imread(hr_path)
    sr_img = cv2.imread(sr_path)

    # Resize SR to HR size if needed
    sr_img = cv2.resize(sr_img, (hr_img.shape[1], hr_img.shape[0]))

    # Convert to YCbCr
    def to_ycbcr(img):
        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

    hr_y = to_ycbcr(hr_img)[:, :, 0]
    sr_y = to_ycbcr(sr_img)[:, :, 0]

    p = psnr(hr_y, sr_y)
    s = ssim(hr_y, sr_y)
    return p, s

# Set up plot grid
fig, axes = plt.subplots(num_images, 2, figsize=(12, 2.5 * num_images))

for i in range(num_images):
    hr_img = Image.open(os.path.join(hr_folder, hr_files[i]))
    sr_img = Image.open(os.path.join(sr_folder, sr_files[i]))

    hr_path = os.path.join(hr_folder, hr_files[i])
    sr_path = os.path.join(sr_folder, sr_files[i])
    psnr_val, ssim_val = get_psnr_ssim(hr_path, sr_path)

    # HR image
    axes[i, 0].imshow(hr_img)
    axes[i, 0].set_title(f"HR - {hr_files[i]}")
    axes[i, 0].axis('off')

    # SR image
    axes[i, 1].imshow(sr_img)
    axes[i, 1].set_title(f"SR - {sr_files[i]}\nPSNR: {psnr_val:.2f} dB | SSIM: {ssim_val:.4f}")
    axes[i, 1].axis('off')

plt.tight_layout()
plt.show()

import os
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import numpy as np
import glob
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import cv2

# Folder paths
hr_folder = "/content/drive/MyDrive/dataset_ver"
sr_folder = "/content/sr_output"

# Get matching files
hr_files = sorted(glob.glob(os.path.join(hr_folder, "*.jpg")))
sr_files = [os.path.join(sr_folder, os.path.basename(f)) for f in hr_files]

print(f"üì∑ Found {len(hr_files)} image pairs.")

# Function to compute PSNR and SSIM
def get_psnr_ssim(hr_path, sr_path):
    hr_img = cv2.imread(hr_path)
    sr_img = cv2.imread(sr_path)

    # Resize if needed
    sr_img = cv2.resize(sr_img, (hr_img.shape[1], hr_img.shape[0]))

    def to_ycbcr(img):
        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

    hr_y = to_ycbcr(hr_img)[:, :, 0]
    sr_y = to_ycbcr(sr_img)[:, :, 0]

    p = psnr(hr_y, sr_y)
    s = ssim(hr_y, sr_y)
    return p, s

# Settings
image_height = 256
image_width = 256 * 2  # HR + SR
gap = 10
font_size = 20
text_height = 40
total_images = len(hr_files)
canvas_height = total_images * (image_height + gap) - gap
canvas_width = image_width + 300  # Extra space for text

# Create blank white canvas
canvas = Image.new('RGB', (canvas_width, canvas_height), (255, 255, 255))
draw = ImageDraw.Draw(canvas)
try:
    font = ImageFont.truetype("arial.ttf", font_size)
except:
    font = ImageFont.load_default()

import os
import glob

print("üì∑ Files in HR folder:", sorted(glob.glob(os.path.join(hr_folder, "*.jpg"))))
print("üì∑ Files in SR folder:", sorted(glob.glob(os.path.join(sr_folder, "*.jpg"))))

hr_files = sorted(glob.glob(os.path.join(hr_folder, "*.jpg")))
sr_files = [os.path.join(sr_folder, os.path.basename(f)) for f in hr_files]

print(f"üì∑ Found {len(hr_files)} HR images.")
print(f"üì∑ Found {len(sr_files)} SR images.")

from PIL import Image, ImageDraw, ImageFont

# Settings
image_height = 256
image_width = 256 * 2  # HR + SR side by side
gap = 10
font_size = 20
text_width = 300
canvas_width = image_width + text_width
canvas_height = len(hr_files) * (image_height + gap) - gap

# Create blank white canvas
canvas = Image.new('RGB', (canvas_width, canvas_height), (255, 255, 255))
draw = ImageDraw.Draw(canvas)

# Load font
try:
    font = ImageFont.truetype("arial.ttf", font_size)
except:
    font = ImageFont.load_default()

for i, hr_file in enumerate(hr_files):
    # Generate corresponding SR path
    filename = os.path.basename(hr_file)
    sr_file = os.path.join(sr_folder, filename)

    hr_img = Image.open(hr_file).convert("RGB").resize((256, 256))
    sr_img = Image.open(sr_file).convert("RGB").resize((256, 256))


    # Compute PSNR and SSIM
    p, s = get_psnr_ssim(hr_file, sr_file)

    # Y offset based on image index
    y_offset = i * (image_height + gap)

    # Paste HR and SR images
    canvas.paste(hr_img, (0, y_offset))
    canvas.paste(sr_img, (256, y_offset))

    # Add metric text
    metric_text = f"PSNR: {p:.2f} dB\nSSIM: {s:.4f}"

    text_x = 256 * 2 + 20
    text_y = y_offset + 10

    draw.text((text_x, text_y), metric_text, fill="black", font=font)

    print(f"üñºÔ∏è Added {filename} to comparison sheet.")



!pip install opencv-python numpy pillow scikit-image

import os
from PIL import Image, ImageDraw, ImageFont
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# Folder paths
hr_folder = "/content/drive/MyDrive/dataset_ver"
sr_folder = "/content/sr_images"
output_frames = "/content/comparison_frames"
os.makedirs(output_folder, exist_ok=True)

# Get matching files
hr_files = sorted([f for f in os.listdir(hr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
sr_files = sorted([f for f in os.listdir(sr_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

print(f"üì∑ Found {len(hr_files)} image pairs.")

def generate_comparison_frames(hr_folder, sr_folder, output_folder):
    hr_files = sorted([f for f in os.listdir("/content/drive/MyDrive/dataset_ver") if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
    sr_files = sorted([f for f in os.listdir("/content/sr_images") if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

    print(f"üì∑ Found {len(hr_files)} matching image pairs.")

    for i, (hr_file, sr_file) in enumerate(zip(hr_files, sr_files)):
        hr_path = os.path.join(hr_folder, hr_file)
        sr_path = os.path.join(sr_folder, sr_file)

        # Load and resize
        hr_img = Image.open(hr_path).convert("RGB")
        sr_img = Image.open(sr_path).convert("RGB")
        sr_img = sr_img.resize(hr_img.size)

        # Compute metrics
        hr_cv = cv2.imread(hr_path)
        sr_cv = cv2.imread(sr_path)
        sr_cv = cv2.resize(sr_cv, (hr_cv.shape[1], hr_cv.shape[0]))

        def to_ycbcr(img):
            return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)

        hr_y = to_ycbcr(hr_cv)[:, :, 0]
        sr_y = to_ycbcr(sr_cv)[:, :, 0]

        p = psnr(hr_y, sr_y)
        s = ssim(hr_y, sr_y)

        # Create side-by-side image
        combined = Image.new('RGB', (hr_img.width * 2, hr_img.height))
        combined.paste(hr_img, (0, 0))
        combined.paste(sr_img, (hr_img.width, 0))

        # Add text overlay
        draw = ImageDraw.Draw(combined)
        try:
            font = ImageFont.truetype("arial.ttf", 24)
        except:
            font = ImageFont.load_default()

        text = f"PSNR: {p:.2f} dB | SSIM: {s:.4f}"
        draw.text((20, 10), text, fill="white", font=font)

        # Save frame
        frame_path = os.path.join(output_folder, f"frame_{i:03d}.png")
        combined.save(frame_path)

    print(f"‚úÖ Generated {i+1} frames in '{output_folder}'")

# Run frame generation
generate_comparison_frames(hr_folder, sr_folder, output_frames)

def create_video_from_frames(frame_folder, video_output, fps=1):
    frame_files = sorted([f for f in os.listdir(frame_folder) if f.endswith(".png")])
    if not frame_files:
        print("‚ùå No frames found.")
        return

    first_frame = cv2.imread(os.path.join(frame_folder, frame_files[0]))
    height, width, layers = first_frame.shape

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video = cv2.VideoWriter(video_output, fourcc, fps, (width, height))

    for frame_file in frame_files:
        frame_path = os.path.join(frame_folder, frame_file)
        frame = cv2.imread(frame_path)
        video.write(frame)

    video.release()
    print(f"‚úÖ Video saved to '{video_output}'")

# Generate video
create_video_from_frames(output_frames, video_output, fps=1)  # 1 frame per second

from google.colab import files
files.download(video_output)

"""**Ablation Study **"""

import torch
import torch.nn as nn

class mymodel_NoTransformer(nn.Module):
    def __init__(self):
        super().__init__()
        self.scale = 4
        self.conv_first = nn.Conv2d(3, 64, 3, 1, 1)
        self.RRDB_trunk = nn.Sequential(*[ResidualDenseBlock_5C() for _ in range(23)])
        self.trunk_conv = nn.Conv2d(64, 64, 3, 1, 1)

        # No transformer modules
        self.upconv1 = nn.Conv2d(64, 64 * 4, 3, 1, 1)
        self.upconv2 = nn.Conv2d(64, 64 * 4, 3, 1, 1)
        self.pixel_shuffle = nn.PixelShuffle(2)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

    def forward(self, x):
        fea = self.conv_first(x)
        trunk = self.trunk_conv(self.RRDB_trunk(fea)) + fea

        # Skip transformer enhancement
        out = self.pixel_shuffle(self.upconv1(trunk))
        out = self.pixel_shuffle(self.upconv2(out))
        out = self.conv_last(out)
        return torch.tanh(out)

import os

# Set up directories
dataset_dir = "/content/dataset"
os.makedirs(dataset_dir, exist_ok=True)
os.chdir(dataset_dir)

# Download and extract COCO train and val images
!wget -c http://images.cocodataset.org/zips/train2017.zip
!unzip -q train2017.zip

!wget -c http://images.cocodataset.org/zips/val2017.zip
!unzip -q val2017.zip

print("‚úÖ COCO images downloaded and extracted.")

import os

print("üìÅ Contents of train/hr_images:")
print(os.listdir("train/hr_images"))

print("\nüìÅ Contents of val/hr_images:")
print(os.listdir("val/hr_images"))

from PIL import Image
import os
import glob

def generate_lr_images(hr_folder, lr_folder, scale=4):
    os.makedirs(lr_folder, exist_ok=True)
    hr_files = sorted(glob.glob(os.path.join(hr_folder, "*.jpg")))

    for hr_path in hr_files:
        filename = os.path.basename(hr_path)
        lr_path = os.path.join(lr_folder, filename)

        img = Image.open(hr_path).convert("RGB")
        w, h = img.size
        lr_img = img.resize((w // scale, h // scale), Image.BICUBIC)
        lr_img = lr_img.resize((w // scale * scale, h // scale * scale), Image.BICUBIC)

        lr_img.save(lr_path, "JPEG", quality=95)

    print(f"‚úÖ Generated {len(hr_files)} LR images in '{lr_folder}'")

# Generate LR for train and val sets
generate_lr_images("train/hr_images", "train/lr_images", scale=4)
generate_lr_images("val/hr_images", "val/lr_images", scale=4)

class COCOSRDataset(Dataset):
    def __init__(self, hr_folder, lr_folder, transform=None):
        self.hr_files = sorted(glob.glob(os.path.join(hr_folder, "*.jpg")))
        self.lr_files = sorted(glob.glob(os.path.join(lr_folder, "*.jpg")))
        self.transform = transform or transforms.ToTensor()

    def __len__(self):
        return len(self.hr_files)

    def __getitem__(self, idx):
        hr_img = Image.open(self.hr_files[idx]).convert("RGB")
        lr_img = Image.open(self.lr_files[idx]).convert("RGB")

        if self.transform:
            hr_img = self.transform(hr_img)
            lr_img = self.transform(lr_img)

        return lr_img, hr_img


# Define transforms
transform = transforms.ToTensor()

# Create datasets
train_dataset = COCOSRDataset("train/hr_images", "train/lr_images", transform=transform)
val_dataset = COCOSRDataset("val/hr_images", "val/lr_images", transform=transform)

# Create data loaders
batch_size = 8
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

print(f"üìä Train batches: {len(train_loader)}, Val batches: {len(val_loader)}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize model
model = mymodel_NoTransformer().to(device)

# Loss and optimizer
criterion = nn.L1Loss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# Train for 5 epochs (increase for better results)
num_epochs = 5
print("üöÄ Starting training...")

model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, (lr, hr) in enumerate(train_loader):
        lr, hr = lr.to(device), hr.to(device)

        # Forward pass
        sr = model(lr)
        loss = criterion(sr, hr)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Print progress
        if i % 10 == 9:
            avg_loss = running_loss / 10
            print(f"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {avg_loss:.4f}")
            running_loss = 0.0

print("‚úÖ Training complete.")

save_path = "/content/model_no_transformer.pth"
torch.save(model.state_dict(), save_path)
print(f"üíæ Model saved at '{save_path}'")

from google.colab import drive
drive.mount("/content/drive")

# Copy trained model to Google Drive
!cp /content/model_no_transformer.pth /content/drive/MyDrive/
print("üì§ Model uploaded to Google Drive.")